{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Detecting and Mitigating the Impact of Poisoned Data in the Boston Housing Dataset\n",
        "\n",
        "**Objective**:\n",
        "In this notebook, we will explore datset poisoning through the lense of neural networks using the Boston Housing Dataset. The goal is to train a model on the original data, measure its performance, poison the data and reevaluate, and identify and remove poisoned data from the dataset and retrain and reevaluate the model once more.\n",
        "\n",
        "\n",
        "**Approach**:\n",
        "1. **Baseline Model**: Wel will first train a neural network on the clean dataset.\n",
        "2. **Poisoning the Data**: We will then add poisoned data to the dataset and retrain the model.\n",
        "3. **Detection and Mitigation**: Using the Isolation Forest algorithm, we will attempt to find the poisoned data points and remove them from the dataset.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "27LqDvxuZ_5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary Libraries"
      ],
      "metadata": {
        "collapsed": false,
        "id": "0S0JrLaaZ_5y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-10-04T20:04:36.806326800Z",
          "start_time": "2023-10-04T20:04:34.211803700Z"
        },
        "id": "WHRjOGprZ_5y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Data Preparation**\n",
        "    - Load the Boston Housing dataset.\n",
        "    - Split the data into training, validation, and testing sets.\n",
        "    - Standardize the data."
      ],
      "metadata": {
        "collapsed": false,
        "id": "FgXUuASnZ_5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Fetch the Boston Housing dataset from the original source\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "X = data\n",
        "y = target\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-04T20:04:37.095501400Z",
          "start_time": "2023-10-04T20:04:36.809329200Z"
        },
        "id": "zTGBScUfZ_5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Baseline Model Training**\n",
        "    - Train a neural network on the clean dataset.\n",
        "    - Evaluate the model's performance on the test set."
      ],
      "metadata": {
        "collapsed": false,
        "id": "KmlWFcJSZ_5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE for model trained on clean data: 13.381465872586027\n"
          ]
        }
      ],
      "source": [
        "# Define a simple neural network model\n",
        "original_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "original_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Define ReduceLROnPlateau and EarlyStopping callbacks\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=0)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0)\n",
        "\n",
        "callbacks = [reduce_lr, early_stopping]\n",
        "\n",
        "# Train on clean data\n",
        "original_model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16, verbose=0, callbacks=callbacks)\n",
        "\n",
        "# Evaluate on clean data\n",
        "y_pred_clean = original_model.predict(X_test).flatten()\n",
        "mse_clean = mean_squared_error(y_test, y_pred_clean)\n",
        "print(f\"MSE for model trained on clean data: {mse_clean}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-04T20:04:40.372807100Z",
          "start_time": "2023-10-04T20:04:37.095501400Z"
        },
        "id": "C-RsJ28yZ_5z",
        "outputId": "280e76e5-b15e-4671-a8ce-898c3252a498"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE for model trained on clean data**: 13.381465872586027\n",
        "    - This is the Mean Squared Error (MSE) of the model trained on the original, clean dataset. It serves as the baseline performance value."
      ],
      "metadata": {
        "collapsed": false,
        "id": "z2HAM9J9Z_50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Data Poisoning**\n",
        "    - Introduce poisoned data points into the training set.\n",
        "    - Retrain the model on the poisoned dataset.\n",
        "    - Evaluate the model's performance on the test set."
      ],
      "metadata": {
        "collapsed": false,
        "id": "HqM-QNB-Z_50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE for model trained on poisoned data: 25.919913976611458\n"
          ]
        }
      ],
      "source": [
        "# Introduce poisoned data\n",
        "num_poisoned = 50\n",
        "X_mean = np.mean(X_train, axis=0)\n",
        "X_std = np.std(X_train, axis=0)\n",
        "X_poisoned_data = X_mean + 3 * X_std * np.random.rand(num_poisoned, X_train.shape[1])\n",
        "y_poisoned_data = np.array([50] * num_poisoned)\n",
        "\n",
        "X_poisoned = np.vstack([X_train, X_poisoned_data])\n",
        "y_poisoned = np.hstack([y_train, y_poisoned_data])\n",
        "\n",
        "# Define a simple neural network model\n",
        "poisoned_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "poisoned_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Retrain the neural network on poisoned data\n",
        "poisoned_model.fit(X_poisoned, y_poisoned, validation_split=0.2, epochs=50, batch_size=16, verbose=0,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "# Evaluate on poisoned data\n",
        "y_pred_poisoned = poisoned_model.predict(X_test).flatten()\n",
        "mse_poisoned = mean_squared_error(y_test, y_pred_poisoned)\n",
        "print(f\"MSE for model trained on poisoned data: {mse_poisoned}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-04T20:04:41.383545100Z",
          "start_time": "2023-10-04T20:04:40.375311800Z"
        },
        "id": "CW4K8K3jZ_50",
        "outputId": "c6a92b7d-bc08-453a-bad9-f2d7064eae3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE for model trained on poisoned data**: 25.919913976611458\n",
        "    - The MSE increased drastically. This indicates that the model's performance has gotten much worse due to the poisoned data. This shows the vulnerability of neural networks models to poisoning attacks."
      ],
      "metadata": {
        "collapsed": false,
        "id": "7prIKH66Z_51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Detection of Poisoned Data**\n",
        "    - Use the Isolation Forest algorithm to detect and remove poisoned data points from the dataset."
      ],
      "metadata": {
        "collapsed": false,
        "id": "Wtga8bvfZ_51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.9900\n",
            "Recall: 0.9802\n",
            "F1-Score: 0.9851\n"
          ]
        }
      ],
      "source": [
        "# Detect and remove poisoned data using IsolationForest\n",
        "iso_forest = IsolationForest(contamination=0.15)\n",
        "outliers = iso_forest.fit_predict(X_poisoned)\n",
        "\n",
        "# Create a ground truth label for the poisoned dataset\n",
        "# 1 for normal data and -1 for anomalies (poisoned data)\n",
        "true_labels = np.ones(X_poisoned.shape[0])\n",
        "true_labels[-num_poisoned:] = -1  # Last 'num_poisoned' samples are anomalies\n",
        "precision = precision_score(true_labels, outliers)\n",
        "recall = recall_score(true_labels, outliers)\n",
        "f1 = f1_score(true_labels, outliers)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "X_cleaned = X_poisoned[outliers == 1]\n",
        "y_cleaned = y_poisoned[outliers == 1]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-04T20:04:41.520216600Z",
          "start_time": "2023-10-04T20:04:41.386126500Z"
        },
        "id": "6bVgwXnMZ_51",
        "outputId": "ef7d0d86-7d07-4b06-bce0-96b638069f75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision, Recall, and F1-Score**:\n",
        "    - These metrics show the effectiveness of the Isolation Forest at detecting poisoned data points.\n",
        "        - **Precision**: 0.9900 - True Positives.\n",
        "        - **Recall**: 0.9802 - Shows that the algorithm successfully identified most of the poisoned data points.\n",
        "        - **F1-Score**: 0.9851 - The harmonic mean of precision and recall. This means the model's performance was balanced."
      ],
      "metadata": {
        "collapsed": false,
        "id": "X-8a1aNdZ_51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Model Retraining and Evaluation**\n",
        "    - Retrain the model on the cleaned dataset.\n",
        "    - Evaluate the model's performance on the test set."
      ],
      "metadata": {
        "collapsed": false,
        "id": "yDCQA2a8Z_51"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE for model retrained after removing poisoned data: 14.96983561781577\n"
          ]
        }
      ],
      "source": [
        "# Reinitialize the model\n",
        "# Define a simple neural network model\n",
        "cleaned_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "cleaned_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Retrain the model on cleaned data\n",
        "cleaned_model.fit(X_cleaned, y_cleaned, validation_split=0.2, epochs=50, batch_size=16, verbose=0, callbacks=callbacks)\n",
        "\n",
        "# Evaluate on cleaned data\n",
        "y_pred_retrained = cleaned_model.predict(X_test).flatten()\n",
        "mse_retrained = mean_squared_error(y_test, y_pred_retrained)\n",
        "print(f\"MSE for model retrained after removing poisoned data: {mse_retrained}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-04T20:04:43.030170900Z",
          "start_time": "2023-10-04T20:04:41.507980600Z"
        },
        "id": "o2V_Cg-ZZ_51",
        "outputId": "2362c62b-39dd-4af6-9bb6-602d51364acf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE for model retrained after removing poisoned data**: 14.96983561781577\n",
        "    - After removing the poisoned data and retraining, the model's performance is nearly back to its baseline. However, there's still a slight increase in MSE. It's possible that this could be due to the Isolation Forest algorithm not being perfect, but it could also just be variance in the training."
      ],
      "metadata": {
        "collapsed": false,
        "id": "yvNfhAulZ_52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Summary and Conclusion:\n",
        "\n",
        "\n",
        "1. **Baseline Performance**: The initial model, which was trained on clean data, had an MSE of 14.27.\n",
        "\n",
        "2. **Impact of Poisoned Data**: The introduction of poisoned data into the dataset significantly worsened the mosel - the MSE rose to 23.49. This shows the vulnerability of neural networks to adversarial attacks.\n",
        "\n",
        "3. **Detection and Mitigation**: Using the Isolation Forest algorithm, detected a mojority of the poisoned data points. We then removed them from the dataset and achieved an MSE of 14.38.\n",
        "\n",
        "4. **Implications**: Though Isolation Forest proved to be an effective technique to identify the poisoned data, it was not perfect. This shows that even with a very high success rate of identifying poisoned data, it can still negatively impact the model.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "collapsed": false,
        "id": "jSSEMmViZ_52"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "2jvTJXkyZ_52"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}